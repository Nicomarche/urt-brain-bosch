# Sistema de Seguimiento de Lﾃｭneas con OpenCV

## Descripciﾃｳn
Este sistema permite que el vehﾃｭculo siga automﾃ｡ticamente las lﾃｭneas de la pista cuando estﾃ｡ en modo AUTO. Utiliza OpenCV para detectar lﾃｭneas blancas y amarillas, y controla automﾃ｡ticamente el steering (direcciﾃｳn) y la velocidad del vehﾃｭculo.

## Cﾃｳmo Funcionar

### 1. Activar el Modo AUTO
Para activar el seguimiento de lﾃｭneas, simplemente cambia el sistema a modo AUTO desde el dashboard. El sistema automﾃ｡ticamente:
- Habilita la cﾃ｡mara
- Activa el thread de seguimiento de lﾃｭneas
- Comienza a enviar comandos de control al vehﾃｭculo

### 2. Funcionamiento Automﾃ｡tico
El sistema:
- **Detecta lﾃｭneas**: Identifica lﾃｭneas blancas y amarillas en la pista
- **Calcula la direcciﾃｳn**: Determina el ﾃ｡ngulo de steering necesario
- **Ajusta la velocidad**: Reduce velocidad en curvas cerradas
- **Controla el vehﾃｭculo**: Envﾃｭa comandos continuos de steering y speed

## Parﾃ｡metros Configurables

Puedes ajustar estos parﾃ｡metros en [`threadLineFollowing.py`](src/hardware/camera/threads/threadLineFollowing.py):

### Velocidad
```python
self.base_speed = 0.2        # Velocidad base
self.max_speed = 0.35        # Velocidad mﾃ｡xima en rectas
self.min_speed = 0.15        # Velocidad mﾃｭnima en curvas
```

### Steering (Direcciﾃｳn)
```python
self.max_steering = 25.0              # ﾃ］gulo mﾃ｡ximo de giro (grados)
self.steering_sensitivity = 0.8       # Sensibilidad (0-1): mﾃ｡s alto = mﾃ｡s reactivo
```

### Regiﾃｳn de Interﾃｩs (ROI)
```python
self.roi_height_start = 0.5       # Inicio del ﾃ｡rea de detecciﾃｳn (50% de altura)
self.roi_height_end = 0.9         # Fin del ﾃ｡rea de detecciﾃｳn (90% de altura)
self.roi_width_margin = 0.15      # Margen lateral (15% cada lado = 70% centro)
```

### Detecciﾃｳn de Color (HSV)

**Lﾃｭneas Blancas:**
```python
self.white_lower = np.array([0, 0, 200])
self.white_upper = np.array([180, 30, 255])
```

**Lﾃｭneas Amarillas:**
```python
self.yellow_lower = np.array([20, 100, 100])
self.yellow_upper = np.array([30, 255, 255])
```

## Modo Debug

Para activar la visualizaciﾃｳn en tiempo real, modifica en [`processCamera.py`](src/hardware/camera/processCamera.py):

```python
lineFollowingTh = threadLineFollowing(
    self.queuesList, self.logging, self.debugging, 
    show_debug=True  # Cambia a True para ver el debug
)
```

Esto mostrarﾃ｡ una ventana con:
- 笨 Lﾃｭneas detectadas (verde)
- 沐ｵ Regiﾃｳn de interﾃｩs (azul)
- 沐ｴ Lﾃｭnea central de referencia
- 沺｣ Centro de lﾃｭneas detectado
- 沒 Valores de steering y speed

## Ajustes Recomendados

### Si el carro va muy rﾃ｡pido:
```python
self.base_speed = 0.15
self.max_speed = 0.25
```

### Si el carro no gira suficiente:
```python
self.max_steering = 30.0
self.steering_sensitivity = 1.0
```

### Si el carro gira demasiado:
```python
self.steering_sensitivity = 0.5
self.max_steering = 20.0
```

### Si no detecta las lﾃｭneas:
1. Ajusta los valores HSV segﾃｺn la iluminaciﾃｳn
2. Aumenta el ﾃ｡rea de ROI:
```python
self.roi_height_start = 0.3
self.roi_height_end = 0.95
```

## Sistema Adaptativo de Iluminaciﾃｳn (NUEVO)

El sistema ahora incluye tﾃｩcnicas avanzadas para manejar cambios de luz automﾃ｡ticamente:

### CLAHE (Ecualizaciﾃｳn de Histograma Adaptativo)
Normaliza la iluminaciﾃｳn antes de procesar la imagen. Muy ﾃｺtil para sombras y zonas brillantes.

```python
self.use_clahe = True              # Activar/desactivar
self.clahe_clip_limit = 2.0        # Lﾃｭmite de contraste (1.0-5.0)
self.clahe_grid_size = 8           # Tamaﾃｱo de la grilla (4-16)
```

### Detecciﾃｳn Adaptativa de Blanco
En lugar de usar un umbral V fijo, calcula el umbral dinﾃ｡micamente basﾃ｡ndose en el percentil de brillo de la imagen actual.

```python
self.use_adaptive_white = True           # Activar/desactivar
self.adaptive_white_percentile = 92      # Percentil para umbral (80-98)
self.adaptive_white_min_threshold = 180  # Umbral mﾃｭnimo de seguridad
```

### Fallback por Gradiente
Cuando la detecciﾃｳn por color falla (menos del 1% de pﾃｭxeles detectados), usa detecciﾃｳn de bordes como respaldo.

```python
self.use_gradient_fallback = True   # Activar/desactivar
self.gradient_percentile = 85       # Percentil para detecciﾃｳn de bordes
```

### Recomendaciones para diferentes condiciones de luz:

**Luz muy variable (nubes, sombras):**
```python
self.use_clahe = True
self.clahe_clip_limit = 3.0
self.use_adaptive_white = True
self.adaptive_white_percentile = 90
```

**Luz artificial intensa:**
```python
self.clahe_clip_limit = 1.5
self.adaptive_white_min_threshold = 200
```

**Condiciones oscuras:**
```python
self.clahe_clip_limit = 4.0
self.adaptive_white_percentile = 85
self.use_gradient_fallback = True
```

### Si detecta demasiadas cosas falsas (objetos del costado):
1. Aumenta el margen lateral para visiﾃｳn mﾃ｡s estrecha:
```python
self.roi_width_margin = 0.20  # 60% de ancho central
```
2. Ajusta los umbrales HSV para ser mﾃ｡s restrictivos

### Si no detecta lﾃｭneas punteadas:
1. Ajusta los parﾃ｡metros de Hough para segmentos cortos:
```python
# En la funciﾃｳn process_frame() - ya configurado para lﾃｭneas punteadas
lines = cv2.HoughLinesP(
    edges,
    rho=1,
    theta=np.pi / 180,
    threshold=30,        # Umbral bajo para segmentos pequeﾃｱos
    minLineLength=20,    # Segmentos cortos de lﾃｭneas punteadas
    maxLineGap=150       # Gap grande para conectar puntos
)
```

### Si detecta lﾃｭneas continuas sﾃｳlidas:
1. Para lﾃｭneas mﾃ｡s continuas, aumenta los valores:
```python
threshold=70,        # Aumenta para ser mﾃ｡s estricto
minLineLength=50,    # Aumenta para lﾃｭneas mﾃ｡s largas
maxLineGap=80        # Reduce para lﾃｭneas mﾃ｡s continuas
```

## Caracterﾃｭsticas Adicionales

### Control Adaptativo de Velocidad
El sistema reduce automﾃ｡ticamente la velocidad en curvas cerradas:
- ﾃ］gulo > 15ﾂｰ: velocidad mﾃｭnima
- ﾃ］gulo > 10ﾂｰ: velocidad media
- ﾃ］gulo < 10ﾂｰ: velocidad mﾃ｡xima

### Manejo de Pﾃｩrdida de Lﾃｭnea
Si no detecta lﾃｭneas por varios frames:
- Reduce la velocidad automﾃ｡ticamente
- Mantiene el ﾃｺltimo steering conocido brevemente
- Se detiene si pierde la lﾃｭnea por mucho tiempo

### Filtrado de Ruido
El sistema utiliza:
- Operaciones morfolﾃｳgicas para limpiar la mﾃ｡scara
- Gaussian blur para suavizar
- Detecciﾃｳn de bordes Canny
- Transformada de Hough para lﾃｭneas robustas

## Soluciﾃｳn de Problemas

### El vehﾃｭculo no responde
1. Verifica que estﾃｩs en modo AUTO
2. Confirma que la cﾃ｡mara estﾃｩ funcionando
3. Revisa los logs en la terminal

### Detecciﾃｳn errﾃ｡ctica
1. Activa el modo debug para visualizar
2. Ajusta los valores HSV segﾃｺn la iluminaciﾃｳn de tu pista
3. Modifica el ROI si las lﾃｭneas estﾃ｡n muy cerca o lejos

### Oscilaciﾃｳn excesiva
1. Reduce `steering_sensitivity`
2. Aumenta el suavizado (valores de Gaussian blur)
3. Ajusta los parﾃ｡metros de HoughLinesP

## Archivos Modificados

1. **[`systemMode.py`](src/statemachine/systemMode.py)**: Habilita cﾃ｡mara y line following en modo AUTO
2. **[`threadLineFollowing.py`](src/hardware/camera/threads/threadLineFollowing.py)**: Nuevo thread para seguimiento de lﾃｭneas
3. **[`processCamera.py`](src/hardware/camera/processCamera.py)**: Integra el thread de line following

## Modos de Detecciﾃｳn

El sistema soporta tres modos de detecciﾃｳn de lﾃｭneas:

### 1. OpenCV (por defecto)
Usa HSV + sliding window + polynomial fitting. Rﾃ｡pido y calibrado para la pista BFMC.

### 2. LSTR AI
Usa el modelo LSTR (Lane Shape Prediction with Transformers). Mﾃ｡s robusto a cambios de luz pero requiere modelo ONNX.

### 3. Hybrid (Recomendado)
Usa OpenCV como mﾃｩtodo principal y LSTR como fallback cuando la detecciﾃｳn falla. Mejor de ambos mundos.

Para cambiar el modo, usa el slider "Detection Mode" en el dashboard:
- **0** = OpenCV
- **1** = LSTR AI
- **2** = Hybrid

## Configuraciﾃｳn de LSTR (AI Lane Detection)

LSTR es un modelo de deep learning basado en Transformers que detecta lﾃｭneas de carril de manera end-to-end. Es mﾃ｡s robusto a cambios de iluminaciﾃｳn porque aprende features visuales en lugar de usar umbrales de color.

### Instalaciﾃｳn

1. Instalar ONNX Runtime:
```bash
pip install onnxruntime
```

2. Descargar el modelo ONNX:
```bash
# Crear directorio para modelos
mkdir -p models/lstr

# Descargar desde PINTO's model zoo:
# https://github.com/PINTO0309/PINTO_model_zoo/tree/main/140_LSTR
# Descargar lstr_180x320.onnx (el mﾃ｡s pequeﾃｱo, recomendado para RPi)

# Guardar en: models/lstr/lstr_180x320.onnx
```

### Modelos disponibles

| Modelo | Resoluciﾃｳn | Velocidad | Precisiﾃｳn |
|--------|------------|-----------|-----------|
| lstr_180x320 | 180x320 | Mﾃ｡s rﾃ｡pido | Buena |
| lstr_240x320 | 240x320 | Rﾃ｡pido | Mejor |
| lstr_360x640 | 360x640 | Medio | Alta |
| lstr_480x640 | 480x640 | Lento | Muy alta |
| lstr_720x1280 | 720x1280 | Muy lento | Mﾃ｡xima |

**Recomendaciﾃｳn para Raspberry Pi**: Usar `lstr_180x320` para mejor rendimiento.

### Referencia
- Paper: [End-to-end Lane Shape Prediction with Transformers (WACV 2021)](https://github.com/liuruijin17/LSTR)
- ONNX Models: [PINTO Model Zoo](https://github.com/PINTO0309/PINTO_model_zoo/tree/main/140_LSTR)

## Prﾃｳximas Mejoras Posibles

- 泅ｦ Detecciﾃｳn de semﾃ｡foros y seﾃｱales
- 泅 Detecciﾃｳn de obstﾃ｡culos
- 沒 Control PID para steering mﾃ｡s suave
- 沁ｯ Predicciﾃｳn de trayectoria
- 沐 Filtro de Kalman para suavizado
- 沒 Telemetrﾃｭa y logging de datos
